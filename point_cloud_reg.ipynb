{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba144d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]\n",
      "Exe   : c:\\Users\\lucas\\miniconda3\\envs\\TableOCR\\python.exe\n",
      "Platform: Windows-10-10.0.26100-SP0\n",
      "Site-packages: ['c:\\\\Users\\\\lucas\\\\miniconda3\\\\envs\\\\TableOCR', 'c:\\\\Users\\\\lucas\\\\miniconda3\\\\envs\\\\TableOCR\\\\lib\\\\site-packages']\n",
      "NumPy: 1.26.4 path: c:\\Users\\lucas\\miniconda3\\envs\\TableOCR\\lib\\site-packages\\numpy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, site, pprint\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Exe   :\", sys.executable)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"Site-packages:\", site.getsitepackages())\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"NumPy:\", np.__version__, \"path:\", np.__file__)\n",
    "except Exception as e:\n",
    "    print(\"NumPy import failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1b176b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing cv2: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymupdf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing cv2: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, List, Iterable, Optional, Tuple, Literal\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pymupdf\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import probreg\n",
    "from skimage import transform as sktf, feature as skfeat, filters as skf, morphology as skm, measure\n",
    "\n",
    "# my own funcs\n",
    "from detect import pdf_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94140b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_annotations(ann_path: str) -> dict:\n",
    "    with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    data.setdefault(\"meta\", {})\n",
    "    data.setdefault(\"pages\", {})\n",
    "    # Normalize keys to str->int mapping on the fly\n",
    "    pages = {}\n",
    "    for k, v in data[\"pages\"].items():\n",
    "        try:\n",
    "            pages[int(k)] = v\n",
    "        except Exception:\n",
    "            continue\n",
    "    data[\"pages\"] = pages\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4389974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scale_rect(rect: List[float], from_size: Tuple[float, float], to_size: Tuple[int, int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Scale [x1,y1,x2,y2] from 'from_size' (W,H) to 'to_size' (W,H).\n",
    "    If 'from_size' is (0,0) or missing, assume no scaling needed.\n",
    "    Returns integer pixel coords clamped to destination size.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(float, rect)\n",
    "    fW, fH = from_size\n",
    "    tW, tH = to_size\n",
    "    if fW and fH and (abs(fW - tW) > 1e-3 or abs(fH - tH) > 1e-3):\n",
    "        sx = tW / fW\n",
    "        sy = tH / fH\n",
    "        x1 *= sx; x2 *= sx\n",
    "        y1 *= sy; y2 *= sy\n",
    "\n",
    "    # normalize + clamp\n",
    "    x1i, x2i = sorted((int(round(x1)), int(round(x2))))\n",
    "    y1i, y2i = sorted((int(round(y1)), int(round(y2))))\n",
    "    x1i = max(0, min(x1i, tW))\n",
    "    x2i = max(0, min(x2i, tW))\n",
    "    y1i = max(0, min(y1i, tH))\n",
    "    y2i = max(0, min(y2i, tH))\n",
    "    return [x1i, y1i, x2i, y2i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67549a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resize_normalized(\n",
    "    img: Image.Image,\n",
    "    output_size: Tuple[int, int],\n",
    "    mode: Literal[\"stretch\", \"fit\", \"fill\"] = \"fit\",\n",
    "    fill_color: Tuple[int, int, int] = (255, 255, 255),\n",
    "    resample: int = Image.BICUBIC,\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resize 'img' to EXACTLY output_size according to 'mode':\n",
    "      - stretch: direct resize (may distort)\n",
    "      - fit: letterbox padding to preserve aspect (ImageOps.pad-like but without cropping)\n",
    "      - fill: cover + center-crop (like ImageOps.fit)\n",
    "    \"\"\"\n",
    "    Wt, Ht = output_size\n",
    "    if mode == \"stretch\":\n",
    "        return img.resize((Wt, Ht), resample=resample)\n",
    "\n",
    "    if mode == \"fit\":\n",
    "        # Scale to fit within target, then pad to exact size\n",
    "        fitted = ImageOps.contain(img, (Wt, Ht), method=resample)\n",
    "        canvas = Image.new(\"RGB\" if fitted.mode != \"RGBA\" else \"RGBA\", (Wt, Ht), fill_color)\n",
    "        x = (Wt - fitted.width) // 2\n",
    "        y = (Ht - fitted.height) // 2\n",
    "        canvas.paste(fitted, (x, y))\n",
    "        return canvas\n",
    "\n",
    "    if mode == \"fill\":\n",
    "        # Scale to cover target, then center-crop to exact size\n",
    "        return ImageOps.fit(img, (Wt, Ht), method=resample, centering=(0.5, 0.5))\n",
    "    \n",
    "    raise ValueError(f\"Unknown resize mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a875c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotated_regions(\n",
    "    pdf_path: str,\n",
    "    ann_path: str,\n",
    "    render_dpi: Optional[int] = None,\n",
    "    pages: Optional[Iterable[int]] = None,\n",
    "    save_dir: Optional[str] = None,\n",
    "    color: bool = True,\n",
    "    output_size: Optional[Tuple[int, int]] = None,     # <— NEW\n",
    "    resize_mode: Literal[\"stretch\",\"fit\",\"fill\"] = \"fit\",  # <— NEW\n",
    "    fill_color: Tuple[int, int, int] = (255, 255, 255),    # <— NEW (for padding)\n",
    "    resample: int = Image.BICUBIC,                          # <— NEW\n",
    ") -> Dict[int, List[Image.Image]]:\n",
    "    \"\"\"\n",
    "    Create cropped PIL Images for each annotated rectangle.\n",
    "    If output_size is provided, each crop is converted to that exact size\n",
    "    using the specified resize_mode.\n",
    "    \"\"\"\n",
    "    ann = _load_annotations(ann_path)\n",
    "    meta_dpi = ann.get(\"meta\", {}).get(\"dpi\", None)\n",
    "    dpi = int(render_dpi or (meta_dpi if meta_dpi else 300))\n",
    "\n",
    "    pil_pages = pdf_to_images(pdf_path, pages=pages, dpi=dpi, color=color)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    out: Dict[int, List[Image.Image]] = {}\n",
    "    for p, img in pil_pages.items():\n",
    "        W, H = img.size\n",
    "        page_info = ann[\"pages\"].get(p, {})\n",
    "        src_size = page_info.get(\"size\", [0.0, 0.0])\n",
    "        try:\n",
    "            srcW, srcH = float(src_size[0]), float(src_size[1])\n",
    "        except Exception:\n",
    "            srcW, srcH = 0.0, 0.0\n",
    "        rects = page_info.get(\"rects\", [])\n",
    "\n",
    "        crops: List[Image.Image] = []\n",
    "        for i, rect in enumerate(rects):\n",
    "            x1, y1, x2, y2 = _scale_rect(rect, (srcW, srcH), (W, H))\n",
    "            if x2 - x1 <= 1 or y2 - y1 <= 1:\n",
    "                continue\n",
    "            crop = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "            if output_size is not None:\n",
    "                crop = _resize_normalized(\n",
    "                    crop,\n",
    "                    output_size=output_size,\n",
    "                    mode=resize_mode,\n",
    "                    fill_color=fill_color,\n",
    "                    resample=resample,\n",
    "                )\n",
    "\n",
    "            crops.append(crop)\n",
    "\n",
    "            if save_dir is not None:\n",
    "                suffix = f\"{resize_mode}_{output_size[0]}x{output_size[1]}\" if output_size else \"orig\"\n",
    "                crop_path = os.path.join(save_dir, f\"page_{p+1:03d}_region_{i+1:02d}_{suffix}.png\")\n",
    "                crop.save(crop_path)\n",
    "\n",
    "        out[p] = crops\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0574c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = extract_annotated_regions(pdf_path='1880.pdf',ann_path='1880_annotations.json',render_dpi=300,output_size=(1000,1200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f53828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def pil_to_cv(img: Image.Image) -> np.ndarray:\n",
    "    if img.mode in (\"RGB\", \"RGBA\"):\n",
    "        arr = np.array(img.convert(\"RGB\"))\n",
    "        return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "    elif img.mode == \"L\":\n",
    "        return np.array(img)\n",
    "    else:\n",
    "        arr = np.array(img.convert(\"RGB\"))\n",
    "        return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def cv_to_pil(img: np.ndarray) -> Image.Image:\n",
    "    if img.ndim == 2:\n",
    "        return Image.fromarray(img)\n",
    "    return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def ensure_gray(img_bgr: np.ndarray) -> np.ndarray:\n",
    "    return img_bgr if img_bgr.ndim == 2 else cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def resize_keep(img: np.ndarray, size: Tuple[int,int]) -> np.ndarray:\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Method 1: ORB + Homography\n",
    "# ---------------------------\n",
    "def register_homography(\n",
    "    src_pil: Image.Image,\n",
    "    ref_pil: Image.Image,\n",
    "    out_size: Tuple[int, int],\n",
    "    n_features: int = 3000,\n",
    "    ratio_thresh: float = 0.75,\n",
    ") -> Image.Image:\n",
    "    src = pil_to_cv(src_pil)\n",
    "    ref = pil_to_cv(ref_pil)\n",
    "\n",
    "    src_gray = ensure_gray(src)\n",
    "    ref_gray = ensure_gray(ref)\n",
    "\n",
    "    # ORB features\n",
    "    orb = cv2.ORB_create(nfeatures=n_features, fastThreshold=5, edgeThreshold=5)\n",
    "    kps1, des1 = orb.detectAndCompute(src_gray, None)\n",
    "    kps2, des2 = orb.detectAndCompute(ref_gray, None)\n",
    "    if des1 is None or des2 is None:\n",
    "        # fall back: just resize\n",
    "        return cv_to_pil(resize_keep(src, out_size))\n",
    "\n",
    "    # BF matcher + Lowe ratio test\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) < 8:\n",
    "        return cv_to_pil(resize_keep(src, out_size))\n",
    "\n",
    "    src_pts = np.float32([kps1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kps2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 3.0)\n",
    "    if H is None:\n",
    "        return cv_to_pil(resize_keep(src, out_size))\n",
    "\n",
    "    warped = cv2.warpPerspective(src, H, (ref.shape[1], ref.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "    return cv_to_pil(resize_keep(warped, out_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Method 2: ECC (affine/homography)\n",
    "# ---------------------------\n",
    "def register_ecc(\n",
    "    src_pil: Image.Image,\n",
    "    ref_pil: Image.Image,\n",
    "    out_size: Tuple[int, int],\n",
    "    warp_mode: Literal[\"affine\",\"homography\"] = \"affine\",\n",
    "    n_iter: int = 300,\n",
    "    eps: float = 1e-6,\n",
    ") -> Image.Image:\n",
    "    src = pil_to_cv(src_pil)\n",
    "    ref = pil_to_cv(ref_pil)\n",
    "    src_gray = ensure_gray(src)\n",
    "    ref_gray = ensure_gray(ref)\n",
    "\n",
    "    # Normalize contrast to help ECC\n",
    "    src_gray = cv2.normalize(src_gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    ref_gray = cv2.normalize(ref_gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    if warp_mode == \"homography\":\n",
    "        warp_matrix = np.eye(3, dtype=np.float32)\n",
    "        motion_type = cv2.MOTION_HOMOGRAPHY\n",
    "    else:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        motion_type = cv2.MOTION_AFFINE\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, n_iter, eps)\n",
    "\n",
    "    try:\n",
    "        cc, warp_matrix = cv2.findTransformECC(\n",
    "            ref_gray, src_gray, warp_matrix, motion_type, criteria, None, 5\n",
    "        )\n",
    "    except cv2.error:\n",
    "        return cv_to_pil(resize_keep(src, out_size))\n",
    "\n",
    "    if motion_type == cv2.MOTION_HOMOGRAPHY:\n",
    "        aligned = cv2.warpPerspective(src, warp_matrix, (ref.shape[1], ref.shape[0]),\n",
    "                                      flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "    else:\n",
    "        aligned = cv2.warpAffine(src, warp_matrix, (ref.shape[1], ref.shape[0]),\n",
    "                                 flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    return cv_to_pil(resize_keep(aligned, out_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acda8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Method 3: Piecewise-affine via grid intersections\n",
    "# ---------------------------\n",
    "def _grid_intersections(img_gray: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Heuristic: binarize, extract horizontal/vertical lines, find intersections.\n",
    "    Returns Nx2 array of (x, y) points.\n",
    "    \"\"\"\n",
    "    # Adaptive threshold\n",
    "    th = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                               cv2.THRESH_BINARY_INV, 21, 15)\n",
    "\n",
    "    # Separate horizontal/vertical via morphology\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "\n",
    "    horiz = cv2.morphologyEx(th, cv2.MORPH_OPEN, h_kernel, iterations=1)\n",
    "    vert  = cv2.morphologyEx(th, cv2.MORPH_OPEN, v_kernel, iterations=1)\n",
    "\n",
    "    # intersections ~ AND of dilated lines\n",
    "    inter = cv2.bitwise_and(cv2.dilate(horiz, None, iterations=1),\n",
    "                            cv2.dilate(vert, None, iterations=1))\n",
    "\n",
    "    # Find connected components centroids\n",
    "    num, labels, stats, centroids = cv2.connectedComponentsWithStats(inter, connectivity=8)\n",
    "    pts = centroids[1:] if num > 1 else np.zeros((0, 2), dtype=np.float32)  # skip background\n",
    "    return pts.astype(np.float32)\n",
    "\n",
    "\n",
    "def register_piecewise(\n",
    "    src_pil: Image.Image,\n",
    "    ref_pil: Image.Image,\n",
    "    out_size: Tuple[int, int],\n",
    "    min_points: int = 12,\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Estimates a piecewise-affine warp using detected grid intersections as control points.\n",
    "    Points are matched by sorting in Morton/Z-order after coarse normalization.\n",
    "    Handles mild \"wavy\" bends better than a single homography.\n",
    "    \"\"\"\n",
    "    src = pil_to_cv(src_pil)\n",
    "    ref = pil_to_cv(ref_pil)\n",
    "    src_g = ensure_gray(src)\n",
    "    ref_g = ensure_gray(ref)\n",
    "\n",
    "    src_pts = _grid_intersections(src_g)\n",
    "    ref_pts = _grid_intersections(ref_g)\n",
    "\n",
    "    if len(src_pts) < min_points or len(ref_pts) < min_points:\n",
    "        # Fallback to homography if we don't have enough structure\n",
    "        return register_homography(src_pil, ref_pil, out_size)\n",
    "\n",
    "    # Normalize to [0,1] for coarse layout-based matching\n",
    "    def norm(pts, w, h): return np.column_stack((pts[:,0] / w, pts[:,1] / h))\n",
    "    sN = norm(src_pts, src.shape[1], src.shape[0])\n",
    "    rN = norm(ref_pts, ref.shape[1], ref.shape[0])\n",
    "\n",
    "    # Sort by Morton order to produce deterministic correspondences\n",
    "    def morton_key(xy):\n",
    "        x, y = (xy * 1024).astype(int)\n",
    "        def part1by1(n):\n",
    "            n = (n | (n << 8)) & 0x00FF00FF\n",
    "            n = (n | (n << 4)) & 0x0F0F0F0F\n",
    "            n = (n | (n << 2)) & 0x33333333\n",
    "            n = (n | (n << 1)) & 0x55555555\n",
    "            return n\n",
    "        return part1by1(x) | (part1by1(y) << 1)\n",
    "\n",
    "    s_idx = np.argsort([morton_key(p) for p in sN])\n",
    "    r_idx = np.argsort([morton_key(p) for p in rN])\n",
    "\n",
    "    # Pair the first K points\n",
    "    K = min(len(s_idx), len(r_idx))\n",
    "    s_sel = src_pts[s_idx[:K]]\n",
    "    r_sel = ref_pts[r_idx[:K]]\n",
    "\n",
    "    # Piecewise affine (skimage)\n",
    "    tform = sktf.PiecewiseAffineTransform()\n",
    "    # skimage expects (row, col) = (y, x)\n",
    "    tform.estimate(src=s_sel[:, ::-1], dst=r_sel[:, ::-1])\n",
    "\n",
    "    warped = sktf.warp(src, inverse_map=tform, output_shape=(ref.shape[0], ref.shape[1]), order=3)\n",
    "    warped_u8 = (np.clip(warped, 0, 1) * 255).astype(np.uint8)\n",
    "    if warped_u8.ndim == 2:\n",
    "        warped_u8 = cv2.cvtColor(warped_u8, cv2.COLOR_GRAY2BGR)\n",
    "    return cv_to_pil(resize_keep(warped_u8, out_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Orchestration\n",
    "# ---------------------------\n",
    "def normalize_tables(\n",
    "    crops: Dict[int, List[Image.Image]],\n",
    "    template: Optional[Image.Image] = None,\n",
    "    out_size: Tuple[int, int] = (800, 800),\n",
    "    method: Literal[\"homography\",\"ecc\",\"piecewise\"] = \"homography\",\n",
    "    save_dir: Optional[str] = None,\n",
    ") -> Dict[int, List[Image.Image]]:\n",
    "    \"\"\"\n",
    "    Normalize (deskew/dewarp) each table crop to a consistent size and layout.\n",
    "\n",
    "    Args:\n",
    "        crops: {page_idx: [PIL.Image, ...]} table crops.\n",
    "        template: a reference crop (PIL.Image). If None, first crop becomes the template.\n",
    "        out_size: width, height of normalized output.\n",
    "        method: 'homography' (fast, robust), 'ecc' (intensity), or 'piecewise' (handles wavy grids).\n",
    "        save_dir: optional folder to save normalized images.\n",
    "\n",
    "    Returns:\n",
    "        {page_idx: [PIL.Image, ...]} normalized crops.\n",
    "    \"\"\"\n",
    "    # choose template\n",
    "    if template is None:\n",
    "        for lst in crops.values():\n",
    "            if lst:\n",
    "                template = lst[0]\n",
    "                break\n",
    "    if template is None:\n",
    "        return {k: [] for k in crops.keys()}\n",
    "\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    out: Dict[int, List[Image.Image]] = {}\n",
    "    for p, lst in crops.items():\n",
    "        norm_list: List[Image.Image] = []\n",
    "        for i, img in enumerate(lst):\n",
    "            if method == \"ecc\":\n",
    "                ni = register_ecc(img, template, out_size, warp_mode=\"affine\")\n",
    "            elif method == \"piecewise\":\n",
    "                ni = register_piecewise(img, template, out_size)\n",
    "            else:\n",
    "                ni = register_homography(img, template, out_size)\n",
    "\n",
    "            norm_list.append(ni)\n",
    "            if save_dir:\n",
    "                ni.save(os.path.join(save_dir, f\"page_{p+1:03d}_tbl_{i+1:02d}_{method}.png\"))\n",
    "        out[p] = norm_list\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TableOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
